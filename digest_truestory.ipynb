{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexbadin/miniconda3/envs/db_prep/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from telethon import TelegramClient\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "import openai\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRDENTIALS\n",
    "keys_path = 'keys/'\n",
    "\n",
    "with open(keys_path+'api_keys.json') as f:\n",
    "  credentials = json.loads(f.read())\n",
    "\n",
    "# load TG credentials\n",
    "api_id = credentials['api_id'] \n",
    "api_hash = credentials['api_hash']\n",
    "phone = credentials['phone']\n",
    "\n",
    "#load openai credentials\n",
    "openai_key = credentials['openai_key']\n",
    "\n",
    "# load pinecone credentials\n",
    "pine_key = credentials['pine_key']\n",
    "pine_env = credentials['pine_env']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load news digest from TrueStory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs enclosed in brackets\n",
    "    url_pattern = re.compile(r'\\(https?://\\S+|www\\.\\S+\\)')\n",
    "    text = url_pattern.sub('', text)\n",
    "\n",
    "    # Remove Emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove numbers in brackets at the end\n",
    "    numbers_pattern = re.compile(r'\\(\\d+\\)\\s*$')\n",
    "    text = numbers_pattern.sub('', text)\n",
    "\n",
    "    # Remove non-breaking spaces\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "\n",
    "    #Remove **\n",
    "    text = text.replace('**', '')\n",
    "\n",
    "    # Remove double spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # Remove square brackets\n",
    "    text = text.replace('[', '').replace(']', '')\n",
    "\n",
    "    return text.strip()  # strip() is used to remove leading/trailing white spaces\n",
    "\n",
    "# Apply the function to your list\n",
    "cleaned_texts = [clean_text(text) for text in text_list]\n",
    "header_text = clean_text(header_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_last_message(api_id, api_hash):\n",
    "    async with TelegramClient('session_get_news', api_id, api_hash) as client:\n",
    "        messages = await client.get_messages('truesummary', limit=1)\n",
    "        for message in messages:\n",
    "            text = message.text\n",
    "    # parse the message into texts by boundaries: [❸ and (\n",
    "    text = message.text\n",
    "    text_list = text.split('\\n\\n')\n",
    "    header_test = text_list[0]\n",
    "    if \"Самое важное\" in header_test: exit\n",
    "    text_list = text_list[1:-1]\n",
    "    header_test, text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые резонансные иностранные тексты прошедшей недели. Это материалы, на которые чаще всего ссылались издания из нашего российского выпуска\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Reuters: US says Israel agrees to daily pauses in Gaza attacks but fighting rages on. 9 ноября 2023\\nВласти Израиля согласились приостанавливать военные действия в секторе Газа на четыре часа в день. Такие гуманитарные паузы будут действовать начиная с 9 ноября, сообщил представитель Белого дома Джон Кирби',\n",
       " 'The Times: How a British firm sold tank tech to Russia after the invasion. 6 ноября 2023\\nПо данным издания The Times, Future Technology Devices International из Глазго за год продала России полупроводников и микрочипов более чем на $280 тысяч. Одно из изделий компании нашли в российском танке под Киевом в марте 2022 года',\n",
       " 'The Telegraph: How Israel shot down a ballistic missile in space for the first time. 5 ноября 2023\\nАрмия обороны Израиля с помощью системы Arrow сбила баллистическую ракету за пределами земной атмосферы, что, вероятно, стало первым в истории боевым столкновением, произошедшим в космосе. Об этом сообщает The Telegraph',\n",
       " 'News: U.S., European officials broach topic of peace negotiations with Ukraine, sources say. 4 ноября 2023\\nАмериканские и европейские официальные лица непублично обсуждают с украинским правительством возможность начать мирные переговоры с Россией, чтобы завершить войну. Об этом NBC News рассказали двое американских чиновников — действующий и бывший',\n",
       " 'Al Arabia: Erdogan says Israel’s Netanyahu «no longer someone we can talk to». 4 ноября 2023\\nПрезидент Турции Реджеп Тайип Эрдоган заявил, что отказался от дальнейшего общения с премьер-министром Израиля Биньямином Нетаньяху. Его цитирует Al Arabia',\n",
       " \"Reuters: Hezbollah's anti-ship missiles bolster its threat to US navy. 8 ноября 2023\\nУ ливанской группировки «Хезболла» есть российские противокорабельные ракеты, которые она может применить против американских военных кораблей, сообщает Reuters со ссылкой на источники\",\n",
       " \"Reuters: Russia's Putin to stay in power past 2024, sources say. 6 ноября 2023\\nПрезидент России Владимир Путин решил баллотироваться на новый президентский срок на выборах в марте 2024 года, передает агентство Reuters со ссылкой сразу на шесть неназванных источников\",\n",
       " \"ABC News: Netanyahu to ABC's Muir: 'No cease-fire' without release of hostages. 7 ноября 2023\\nИзраиль не пойдет на прекращение огня в секторе Газа до тех пор, пока не будут освобождены все заложники, захваченные 7 октября боевиками ХАМАС, заявил в интервью ABC News премьер-министр Биньямин Нетаньяху\",\n",
       " 'Times: Over 100 British companies admit breaching sanctions on Russia. 6 ноября 2023\\n127 компаний добровольно сообщили правительству Великобритании о нарушениях санкций за период с начала войны в Украине и до середины мая этого года, сообщает Financial Times',\n",
       " 'Broken Borders: AP & Reuters Pictures of Hamas Atrocities Raise Ethical Questions. 8 ноября 2023\\nReuters: Reuters denies any suggestion it had prior knowledge of Oct. 7 Hamas attack on Israel. AP: AP statement on Gaza freelancers. The New York Times: Statement on Yousef Masoud. 9 ноября 2023\\nАмериканская неправительственная организация HonestReporting заявила, что фотокорреспонденты из сектора Газа, внештатно работающие на западные информагентства Associated Press и Reuters, а также американские телеканал CNN и The New York Times, могли быть в курсе планов нападения террористов палестинского движения ХАМАС на Израиль. В редакциях отрицают все обвинения']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(header_text)\n",
    "cleaned_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize openai\n",
    "openai.api_key = openai_key\n",
    "\n",
    "# initialize pinecone\n",
    "pinecone.init(api_key=pine_key, environment=pine_env)\n",
    "index_name = 'tg-news'\n",
    "\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed request\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get similar news from PINECONE with filters (dates=None, sources=None, stance=None)\n",
    "def get_top_pine(request=None, request_emb=None, dates=None, sources=None, stance=None, model=\"text-embedding-ada-002\", top_n=10):\n",
    "    \"\"\"\n",
    "    Returns top news articles related to a given request and stance, within a specified date range.\n",
    "\n",
    "    Args:\n",
    "        request (str): The request for which to find related news articles.\n",
    "        request_emb (numpy.ndarray): The embedding of the request, if already computed.\n",
    "        dates (list): A list of one or two dates in the format 'YYYY-MM-DD', representing the start and end dates of the date range to search for news articles. If only one date is provided, the end date will be set to today.\n",
    "        stance (str): The stance of the news articles to search for. Must be one of 'positive', 'negative', or 'neutral'.\n",
    "        model (str): The name of the OpenAI model to use for computing embeddings.\n",
    "        top_n (int): The number of top news articles to return.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of two strings:\n",
    "        - The first string contains the summaries of the top news articles.\n",
    "        - The second string contains the links to the top news articles, along with their similarity scores.\n",
    "    \"\"\"\n",
    "    if request_emb is None and request is None:\n",
    "        print('Error: no request')\n",
    "        return\n",
    "    if request_emb is None:\n",
    "        request_emb = get_embedding(request)\n",
    "\n",
    "    dates=dates\n",
    "    stance=stance[0]\n",
    "    # define start and end dates (if end date is not defined, it will be set to today)\n",
    "    if dates:\n",
    "        if len(dates) == 2:\n",
    "            # convert start_date to int\n",
    "            start_date = dates[0]\n",
    "            end_date = dates[1]\n",
    "        else:\n",
    "            start_date = dates[0]\n",
    "            end_date = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        # set range from 2022-02-01 to today\n",
    "        start_date = '2000-02-01'\n",
    "        end_date = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # filtering\n",
    "    start_date = int(datetime.strptime(start_date, '%Y-%m-%d').timestamp())\n",
    "    end_date = int(datetime.strptime(end_date, '%Y-%m-%d').timestamp())\n",
    "\n",
    "    filter = {\n",
    "        \"stance\": { \"$eq\": stance },\n",
    "        \"date\": { \"$gte\": start_date, \"$lte\": end_date }\n",
    "        }\n",
    "\n",
    "    # query pinecone\n",
    "    res = index.query(request_emb, top_k=10, include_metadata=True, filter=filter)\n",
    "    #save results to txt-file\n",
    "    with open('pinecone_results.txt', 'w') as f:\n",
    "        f.write(str(res.to_dict()))\n",
    "    # check if results are empty\n",
    "    if res.to_dict()['matches'] == []:\n",
    "        print('No matches')\n",
    "        return 'No matches', 'No matches'\n",
    "    top_sim_news = pd.DataFrame(res.to_dict()['matches']).join(pd.DataFrame(res.to_dict()['matches'])['metadata'].apply(pd.Series))\n",
    "\n",
    "    # collect links & similarities\n",
    "    top_sim_news['msg_id'] = top_sim_news['id'].apply(lambda x: x.split('_')[-1])\n",
    "    top_sim_news['channel_name'] = top_sim_news['id'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "\n",
    "    top_sim_news['link'] = top_sim_news.apply(lambda x: \"https://t.me/\"+str(x.channel_name)+\"/\"+str(x.msg_id)+\" - \"+str(round(x.score,3)), axis=1)\n",
    "    news_links = '\\n'.join(top_sim_news['link'].tolist())\n",
    "    # collect news\n",
    "    news4request = '\\n'.join(top_sim_news['summary'].tolist())\n",
    "    return news4request, news_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_per_1K(model_name):\n",
    "    if model_name == \"gpt-3.5-turbo\": #4K (~10 news)\n",
    "        price_1K = 0.0015 # price per 1000 characters\n",
    "    if model_name == \"gpt-3.5-turbo-1106\": #16K (~40 news)\n",
    "        price_1K = 0.001 # price per 1000 characters\n",
    "    elif model_name == \"gpt-3.5-turbo-16k\": #16K (~40 news)\n",
    "        price_1K = 0.003\n",
    "    elif model_name == \"gpt-4\": #8K (~20 news)\n",
    "        price_1K = 0.03\n",
    "    elif model_name == \"gpt-4-32k\": #32K (~80 news)\n",
    "        price_1K = 0.06\n",
    "    return price_1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ask OpenAI \n",
    "@retry(stop=stop_after_attempt(6), wait=wait_random_exponential(multiplier=1, max=10))\n",
    "def ask_openai(request, news4request, model_name = \"gpt-3.5-turbo-1106\", tokens_out = 512):\n",
    "\n",
    "    system_content_en = f\"You are given few short news texts in Russian. Based on these texts you need to answer the following question: {request}. \\\n",
    "        First, analyze if the texts provide an answer to the question. \\\n",
    "        If the texts do not provide proper answer, say that. \\\n",
    "        If they do, select the texts relevant to the question ({request}) and summarize them. \\\n",
    "        \\nОтвечай только на русском. Не более 1000 символов.\"\n",
    "\n",
    "    system_content_ru = f\"Тебе будут представлены несколько новостей. На их основе нужно ответить на вопрос: {request}. \\\n",
    "        Сперрва проверь, что новости содержат ответ. \\\n",
    "        Если ответа в новостях нет, так и ответь. \\\n",
    "        Далее, отбери новости, которые отвечают на вопрос ({request}) и сделай но ним резюме. \\\n",
    "        \\nНе более 1000 символов.\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model_name,\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_content_ru\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": news4request\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=tokens_out,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION ask_media to combine all together (TO USE IN TG BOT REQUESTS)\n",
    "def ask_media(request, dates=None, sources=None, stance=None, model_name = \"gpt-3.5-turbo-1106\", tokens_out = 512, full_reply = False):\n",
    "    # check request time\n",
    "    request_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    # get top news\n",
    "    # INPUT: request, dates, sources, stance\n",
    "    # OUTPUT: news4request - list of news texts for openai, news_links - list of links\n",
    "    news4request, news_links = get_top_pine(request, dates=dates, sources=sources, stance=stance, model=\"text-embedding-ada-002\", top_n=10)\n",
    "    # limit number of tokens vs model\n",
    "    if model_name == \"gpt-3.5-turbo-1106\":\n",
    "        # print(type(news4request), len(news4request))\n",
    "        # print(news4request)\n",
    "        news4request = news4request[:8000]\n",
    "    elif model_name == \"gpt-3.5-turbo-16k\":\n",
    "        news4request = news4request[:16000]\n",
    "    elif model_name == \"gpt-4\":\n",
    "        news4request = news4request[:8000]\n",
    "    elif model_name == \"gpt-4-32k\":\n",
    "        news4request = news4request[:32000]\n",
    "    \n",
    "    reply = ask_openai(request, news4request, model_name = model_name, tokens_out = tokens_out)\n",
    "    request_params = f\"Request: {request}; \\nFilters: dates: {dates}; sources: {sources}; stance: {stance}\"\n",
    "    reply_text = reply.choices[0]['message']['content']\n",
    "    n_tokens_used = reply.usage.total_tokens\n",
    "    reply_cost = n_tokens_used / 1000 * price_1K\n",
    "\n",
    "    # write params & reply to file. If file doesn't exist - create it with headers\n",
    "    # check reply time\n",
    "    reply_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    \n",
    "    if not os.path.isfile('openai_chatbot_digest_log.csv'):\n",
    "        with open('openai_chatbot_digest_log.csv', 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['request', 'dates', 'sources', 'stance', 'reply_text', 'reply_cost', 'request_time', 'reply_time', 'model_name', 'n_tokens_used', 'news_links'])\n",
    "    with open('openai_chatbot_digest_log.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([request, dates, sources, stance, reply_text, reply_cost, request_time, reply_time, model_name, n_tokens_used, news_links])\n",
    "    \n",
    "    # return reply for chatbot. If full_reply = False - return only reply_text\n",
    "    if full_reply == False:\n",
    "        return reply_text\n",
    "    else:\n",
    "        return request_params + \"\\n\" + \"Cost per request: \" + str(round(reply_cost,3)) + \". Tokens used: \" + str(n_tokens_used) + \"\\n\\n\" + reply_text + \"\\n\\n\" + news_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE STANCES\n",
    "def compare_stances(request, summaries_list, model_name = \"gpt-3.5-turbo-1106\", tokens_out = 1500, dates = None, stance = None, sources = None):\n",
    "    # check request time\n",
    "    request_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    system_content_en = f\"You are given few texts in Russian from 5 sources on the same subject: {request} \\\n",
    "The structure of the texts is as follows:\\\n",
    "1) name of the source is given in []\\\n",
    "2) the text on the subject above is given.\\\n",
    "You task is to analyse what is similar and what is different in all these texts. First, tell what is similar. Then tell the differences for each source. \\\n",
    "\\nОтвечай только на русском. \"\n",
    "\n",
    "    system_content_ru = f\"Тебе будут представлены несколько текстов из источников на одну тему: {request} \\\n",
    "Структура текстов следующая:\\\n",
    "1) в [] указан источник\\\n",
    "2) далее идет текст на тему выше.\\\n",
    "Твоя задача - проанализировать, что общего и что разного в этих текстах. Сначала скажи, что общего. \\n\\\n",
    "Затем, для каждого источника, скажи, в чем разница в формате: [истчоник] - в чем отличия.\\\n",
    "\\nВсего не более 1500 символов.\"\n",
    "\n",
    "    reply = openai.ChatCompletion.create(\n",
    "    model = model_name,\n",
    "    messages=[\n",
    "            {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_content_ru\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": summaries_list\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=tokens_out,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "    request_params = f\"Topic: {request}\"\n",
    "    reply_text = reply.choices[0]['message']['content']\n",
    "    n_tokens_used = reply.usage.total_tokens\n",
    "    price_1K = get_price_per_1K(model_name)\n",
    "    reply_cost = n_tokens_used / 1000 * price_1K\n",
    "    reply_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    if not os.path.isfile('openai_chatbot.csv'):\n",
    "        with open('openai_chatbot.csv', 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['request', 'dates', 'sources', 'stance', 'reply_text', 'reply_cost', 'request_time', 'reply_time', 'model_name', 'n_tokens_used', 'news_links'])\n",
    "    with open('openai_chatbot.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([request, dates, sources, 'all_summary', reply_text, reply_cost, request_time, reply_time, model_name, n_tokens_used, \"\"])\n",
    "\n",
    "    return request_params + \"\\n\\n\" + reply_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting opeani summary of request 0: Минюст объявил «иностранными агентами» и\n",
      "Summary for stance voenkor added.\n",
      "Summary for stance tv added.\n",
      "Summary for stance inet propaganda added.\n",
      "Summary for stance moder added.\n",
      "Summary for stance altern added.\n",
      "Finished opeani summary of stances\n",
      "Topic: Минюст объявил «иностранными агентами» издания «Кедр» и «Гроза»\n",
      "\n",
      "Общее: Все источники сообщают о том, что Минюст объявил издания \"Кедр\" и \"Гроза\" и их сотрудников \"иностранными агентами\".\n",
      "\n",
      "[voenkor] - Не содержит информации о том, что Минюст объявил издания \"Кедр\" и \"Гроза\" иностранными агентами.\n",
      "\n",
      "[tv] - Указывает на обвинения изданий в распространении недостоверной информации о деятельности органов власти и пропаганде иностранной образовательной организации.\n",
      "\n",
      "[inet propaganda] - Указывает на обвинения изданий в распространении недостоверной информации о политике власти РФ.\n",
      "\n",
      "[moder] - Указывает на обвинения изданий в распространении недостоверной информации о политике российских властей в сфере экологии.\n",
      "\n",
      "[altern] - Указывает на обвинения изданий в распространении недостоверной информации о политике России и пропаганде иностранных образовательных организаций.\n",
      "Sent to TG channel request 0: Минюст объявил «иностранными агентами» и\n",
      "Starting opeani summary of request 1: Макрон призвал Израиль остановить бомбар\n",
      "Summary for stance voenkor added.\n",
      "Summary for stance tv added.\n",
      "Summary for stance inet propaganda added.\n",
      "Summary for stance moder added.\n"
     ]
    }
   ],
   "source": [
    "# FOR SINGLE RUN\n",
    "n_tokens_out = 256\n",
    "full_reply = False\n",
    "request = cleaned_texts[0]\n",
    "dates = []\n",
    "# today date\n",
    "dates.append((datetime.today() - timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "dates.append((datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-1106\"\n",
    "price_1K = get_price_per_1K(model_name)\n",
    "\n",
    "# send header to TG channel\n",
    "header = '!'*20 + '\\n' + header_text + '\\n' + '!'*20 + '\\n'\n",
    "async with TelegramClient('session', api_id, api_hash) as client:\n",
    "    await client.send_message(-1002138728748, header)\n",
    "\n",
    "for i, request in enumerate(cleaned_texts):\n",
    "    print(f\"Starting opeani summary of request {i}: {cleaned_texts[i][:40]}\")\n",
    "    # get summaries for all stances\n",
    "    summary_list = []\n",
    "    for stance in ['voenkor', 'tv', 'inet propaganda', 'moder', 'altern']:\n",
    "        reply_text = ask_media(request, dates=dates, stance=[stance], model_name = model_name, tokens_out = n_tokens_out, full_reply = full_reply)\n",
    "        summary_list.append(str([stance])+ \"\\n\" + reply_text)\n",
    "        # status update\n",
    "        print(f\"Summary for stance {stance} added.\")\n",
    "\n",
    "    summary_list = '\\n\\n'.join(summary_list)\n",
    "    # compare summaries\n",
    "    compare_reply = compare_stances(request, summary_list, model_name = model_name, dates=dates)\n",
    "    print(\"Finished opeani summary of stances\")\n",
    "    print(compare_reply)\n",
    "\n",
    "    # send compare_reply to TG channel\n",
    "    async with TelegramClient('session', api_id, api_hash) as client:\n",
    "        await client.send_message(-1002138728748, compare_reply)\n",
    "        print(f\"Sent to TG channel request {i}: {cleaned_texts[i][:40]}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"На Тамбовском пороховом заводе спустя пять месяцев снова произошел пожар\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = ask_media(r, dates=dates, stance=['tv'], model_name = model_name, tokens_out = n_tokens_out, full_reply = full_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'На Тамбовском пороховом заводе спустя пять месяцев снова произошел пожар. Новости не содержат информации о пожаре на Тамбовском пороховом заводе.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ask_media",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
